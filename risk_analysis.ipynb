{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c6a867-16c9-4340-885e-73e3163d0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/05 14:58:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/05 14:58:29 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/05 14:58:29 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/12/05 14:58:29 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/12/05 14:58:29 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "anj_spark=SparkSession.builder\\\n",
    "                  .appName('parbu_data_risk_rating')\\\n",
    "                   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed6036d-c3ac-4ff1-8244-3e63d6f0ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    " df = anj_spark.read.parquet('hdfs://localhost:9000/machine_learning/trans_train_source/trans_hist_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c8424-3d3d-463c-ac30-063d05200523",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Problem Statement](#problem-statement)\n",
    "- [Analytical Solutions](#analytical-solutions)\n",
    "- [Data Used](#data-used)\n",
    "- [EDA](#eda)\n",
    "- [ML Model](#ml-model)\n",
    "- [Prediction](#prediction)\n",
    "- [Model Performance](#model-performance)\n",
    "- [Final Output](#final-output)\n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bea953-2918-4fbc-8413-f39d1b51b638",
   "metadata": {},
   "source": [
    "# <a id=\"problem-statement\"></a> Problem Statement\n",
    "The bank needs to know whether the constumer is risky or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e8ff0-bf59-4e7c-aba0-ace171d43b38",
   "metadata": {},
   "source": [
    "# <a id=\"analytical-solutions\"></a> Analytical Solutions\n",
    "Logistic Regression is used to overcome above problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf817c-57b5-42ef-a408-3e4c0a93d297",
   "metadata": {},
   "source": [
    "# <a id=\"data-used\"></a> Data Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b11c0c-363d-49ec-a5e9-240da0f04680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+-----+---------+\n",
      "|     acid|month_0|month_1|month_2|month_3|month_4|month_5|month_6|month_7|month_8|month_9|month_10|month_11|month_12|label|eltm_txid|\n",
      "+---------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+-----+---------+\n",
      "|PB3196939|     93|      0|      0|     10|      0|      0|      0|      0|      0|      0|       0|       0|       0|    1|     5068|\n",
      "|PB5290461|     36|      0|      9|      3|      6|      2|      3|      3|      2|      0|       0|       0|       0|    1|     5068|\n",
      "|PB5139315|    158|      0|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|       0|    1|     5068|\n",
      "|PB5485912|      2|      1|      1|      0|      0|      0|      0|      0|      0|      0|       0|       0|       0|    1|     5068|\n",
      "|PB5295373|      1|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|       0|    1|     5068|\n",
      "+---------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0769f5e1-5449-473c-b397-c1fe597960a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acid',\n",
       " 'month_0',\n",
       " 'month_1',\n",
       " 'month_2',\n",
       " 'month_3',\n",
       " 'month_4',\n",
       " 'month_5',\n",
       " 'month_6',\n",
       " 'month_7',\n",
       " 'month_8',\n",
       " 'month_9',\n",
       " 'month_10',\n",
       " 'month_11',\n",
       " 'month_12',\n",
       " 'label',\n",
       " 'eltm_txid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e79b61-fdb7-4b01-b0c3-7f62abe3bc70",
   "metadata": {},
   "source": [
    "# <a id=\"ml-model\"></a> ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def534d0-dfb5-4602-8d74-86b23660e1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 15:05:29 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     acid|Risk_Rating|\n",
      "+---------+-----------+\n",
      "|PB2384524|        Low|\n",
      "|PB2384534|        Low|\n",
      "|PB2384540|        Low|\n",
      "|PB2384542|        Low|\n",
      "|PB2384559|        Low|\n",
      "|PB2384560|        Low|\n",
      "|PB2384562|        Low|\n",
      "|PB2384577|        Low|\n",
      "|PB2384581|        Low|\n",
      "|PB2384584|        Low|\n",
      "|PB2384587|        Low|\n",
      "|PB2384605|        Low|\n",
      "|PB2384610|        Low|\n",
      "|PB2384611|        Low|\n",
      "|PB2384614|        Low|\n",
      "|PB2384620|        Low|\n",
      "|PB2384625|        Low|\n",
      "|PB2384637|        Low|\n",
      "|PB2384653|        Low|\n",
      "|PB2384658|        Low|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "# Assemble features\n",
    "feature_columns = ['month_0', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
    "                   'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "data = df_assembled.select(\"acid\", \"features\", \"label\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "(training_data, test_data) = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "model = rf.fit(training_data)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Area Under ROC: \" + str(auc))\n",
    "\n",
    "# Assign risk ratings\n",
    "get_probability = udf(lambda probability: float(probability[1]), DoubleType())\n",
    "predictions = predictions.withColumn(\"Risk_Probability\", get_probability(col(\"probability\")))\n",
    "\n",
    "risk_udf = udf(lambda prob: \"High\" if prob < 0.3 else \"Medium\" if prob < 0.7 else \"Low\", StringType())\n",
    "predictions = predictions.withColumn(\"Risk_Rating\", risk_udf(col(\"Risk_Probability\")))\n",
    "\n",
    "# Display or save results\n",
    "data=predictions.select(\"acid\", \"Risk_Rating\")\n",
    "\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4f5106-27b1-4573-873d-73a554fe7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     acid|Risk_Rating|\n",
      "+---------+-----------+\n",
      "|PB2384524|        Low|\n",
      "|PB2384534|        Low|\n",
      "|PB2384540|        Low|\n",
      "|PB2384542|        Low|\n",
      "|PB2384559|        Low|\n",
      "|PB2384560|        Low|\n",
      "|PB2384562|        Low|\n",
      "|PB2384577|        Low|\n",
      "|PB2384581|        Low|\n",
      "|PB2384584|        Low|\n",
      "|PB2384587|        Low|\n",
      "|PB2384605|        Low|\n",
      "|PB2384610|        Low|\n",
      "|PB2384611|        Low|\n",
      "|PB2384614|        Low|\n",
      "|PB2384620|        Low|\n",
      "|PB2384625|        Low|\n",
      "|PB2384637|        Low|\n",
      "|PB2384653|        Low|\n",
      "|PB2384658|        Low|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "\n",
    "feature_columns = ['month_0', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
    "                   'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "# Select only required columns for modeling\n",
    "data = df_assembled.select(\"acid\", \"features\", \"label\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "(training_data, test_data) = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "model = rf.fit(training_data)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Area Under ROC: \" + str(auc))\n",
    "\n",
    "# Calculate accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Assign risk ratings\n",
    "get_probability = udf(lambda probability: float(probability[1]), DoubleType())\n",
    "predictions = predictions.withColumn(\"Risk_Probability\", get_probability(col(\"probability\")))\n",
    "\n",
    "risk_udf = udf(lambda prob: \"High\" if prob < 0.3 else \"Medium\" if prob < 0.7 else \"Low\", StringType())\n",
    "predictions = predictions.withColumn(\"Risk_Rating\", risk_udf(col(\"Risk_Probability\")))\n",
    "\n",
    "# Display or save results\n",
    "predictions.select(\"acid\", \"Risk_Rating\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e194f4-f389-4bdb-aae3-dd1244b6a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "feature_columns = ['month_0', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
    "                   'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "# Select only required columns for modeling\n",
    "data = df_assembled.select(\"acid\", \"features\", \"label\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "(training_data, test_data) = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "rf_model = rf.fit(training_data)\n",
    "\n",
    "# Train a Logistic Regression Classifier\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "lr_model = lr.fit(training_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231a282-c4c2-4068-a2f3-0691bbe3c7fd",
   "metadata": {},
   "source": [
    "# <a id=\"prediction\"></a> Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bf974-9aee-4a30-bf72-e3063e0ae5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Prediction](#prediction)\n",
    "- [Model Performance](#model-performance)\n",
    "- [Final Output](#final-output)\n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e1be45-9493-43a5-ab51-a157b4c46637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using Random Forest\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Make predictions using Logistic Regression\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5fe4b-45e5-4cbe-a630-055aa349b8dc",
   "metadata": {},
   "source": [
    "# <a id=\"model-performance\"></a> Model Performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a4388-1500-4ee0-8d06-1b4e4ddfc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest model\n",
    "rf_evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "rf_auc = rf_evaluator.evaluate(rf_predictions)\n",
    "print(\"Random Forest Test Area Under ROC: \" + str(rf_auc))\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "lr_evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "lr_auc = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"Logistic Regression Test Area Under ROC: \" + str(lr_auc))\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "rf_evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rf_accuracy = rf_evaluator_acc.evaluate(rf_predictions)\n",
    "print(\"Random Forest Accuracy: {:.2f}%\".format(rf_accuracy * 100))\n",
    "\n",
    "# Calculate accuracy for Logistic Regression\n",
    "lr_evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "lr_accuracy = lr_evaluator_acc.evaluate(lr_predictions)\n",
    "print(\"Logistic Regression Accuracy: {:.2f}%\".format(lr_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b783b61c-35c5-414d-971e-f3113b4dd1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       1.0|    5|\n",
      "|    1|       1.0|25185|\n",
      "+-----+----------+-----+\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       1.0|    5|\n",
      "|    1|       1.0|25185|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define a function to calculate confusion matrix\n",
    "def confusion_matrix(predictions):\n",
    "    # Group by true label and predicted label and count the occurrences\n",
    "    return predictions.groupBy(\"label\", \"prediction\").count().show()\n",
    "\n",
    "# Calculate confusion matrix for Random Forest\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "confusion_matrix(rf_predictions)\n",
    "\n",
    "# Calculate confusion matrix for Logistic Regression\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "confusion_matrix(lr_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5308a-75ab-4f00-8295-db4e6fa0d128",
   "metadata": {},
   "source": [
    "# <a id=\"conclusion\"></a> Conclusion\n",
    "Both Random Forest and Logistic Regression models are performing similarly, with an exceptionally high accuracy (99.98%) on the test data. This indicates that the models are making very few errors in their predictions.\n",
    "However, the confusion matrices reveal that both models are heavily biased towards predicting the majority class (label 1). This suggests that the models may be overfitting or are influenced by an imbalanced dataset, where the majority class (label 1) dominates the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8f983-9738-4dd0-935f-68f1e285233f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
